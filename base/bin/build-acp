#!/usr/bin/env bash

# Build Artifact Copy (build-acp)
# Copy build artifacts into S3
#
# Usage: build-acp <source> [<subpath>]

set -e # Abort if anything fails
#set -x # Echo commands

## Enable extended globbing features
shopt -s extglob

if [[ "${AWS_ACCESS_KEY_ID}" == "" ]] || [[ "${AWS_SECRET_ACCESS_KEY}" == "" ]] || [[ "${ARTIFACTS_BUCKET_NAME}" == "" ]]; then
	echo "Cannot upload artifacts."
	echo "Please make sure AWS_ACCESS_KEY_ID, AWS_SECRET_ACCESS_KEY and ARTIFACTS_BUCKET_NAME environment variables are configured."
	exit 1
fi

# Configure ARTIFACTS_BASE_URL, unless it has been already defined (trim any trailing slashes)
ARTIFACTS_BASE_URL=${ARTIFACTS_BASE_URL%%+(/):-"https://${ARTIFACTS_BUCKET_NAME}.s3.amazonaws.com"}
# Configure ARTIFACTS_BUCKET_PATH, unless it has been already defined (trim any trailing slashes)
ARTIFACTS_BUCKET_PATH=${ARTIFACTS_BUCKET_PATH%%+(/):-"${REPO_NAME_SAFE}/${BRANCH_NAME_SAFE}-${GIT_COMMIT_HASH}"}
# Configure ARTIFACTS_URL, unless it has been already defined
# By default expecting index.html as the default entry point into the bucket/path
ARTIFACTS_URL=${ARTIFACTS_URL:-"${ARTIFACTS_BASE_URL}/${ARTIFACTS_BUCKET_PATH}/index.html"}

# Sync source (local)
source=${1}
# Sync destination (S3)
destination="s3/${ARTIFACTS_BUCKET_NAME}/${ARTIFACTS_BUCKET_PATH}"
# Allow specifying a subpath within destination (trim any trailing slashes)
if [[ "${2}" != "" ]]; then subpath="${2%%+(/)}/"; fi

# Ensure paths ends with a single trailing slash
# ${VAR%%+(/)} strips out all trailing slashes (requires extglob enabled), then we add a single trailing slash back
ARTIFACTS_BUCKET_PATH="${ARTIFACTS_BUCKET_PATH%%+(/)}/"
destination="${destination%%+(/)}/"

# Print configuration for debugging purposes
echo "Configuration (normalized): "
echo "source='${source}'"
echo "destination='${destination}'"
echo "subpath='${subpath}'"
echo "url='${ARTIFACTS_URL}'"

if [[ "${source}" == "" ]]; then
	echo "Error: Source path missing."
	exit
fi

# Initialize minio client (mc) configuration for S3
# AWS API keys must be set in the build settings
mc config host add s3 https://s3.amazonaws.com ${AWS_ACCESS_KEY_ID} ${AWS_SECRET_ACCESS_KEY}

set -x # Debug ON

# Create bucket if it does not exist
mc mb "s3/${ARTIFACTS_BUCKET_NAME}"
# Upload artifact into the bucket
# TODO: figure out how to skip timestemp checking. Maybe use aws-cli instead on the minio client?
# Looks like mirror does not have any benefit here over cp. Files in build have newer timestamps and are always copied.
mc mirror --overwrite --remove ${source} ${destination}${subpath}
# Set download (read-only) policy on BUCKET_PATH
# Access is possible only if BUCKET_PATH is known (parent bucket stays private => XML listing of bucket objects disabled)
# Note: ${destination} is used here instead of ${destination}${subpath} to minimize the number of S3 policy rules when
# multiple subpaths are used within the same destination.
mc policy set download ${destination}

set +x # Debug OFF

echo "Build artifacts upload completed:"
echo "${ARTIFACTS_URL}"
echo "Files:"
mc ls ${destination}

# Post artifacts to Bitbucket build status API
if [[ "${BITBUCKET_CI}" != "" ]] && [[ "${BITBUCKET_TOKEN}" != "" ]]; then
	echo "Posting artifacts URL to Bitbucket..."

	BUILD_STATUS_URL="${ARTIFACTS_URL}"
	PAYLOAD="{\"key\": \"artifacts\", \"state\": \"SUCCESSFUL\", \"name\": \"Build artifacts\", \"url\": \"${BUILD_STATUS_URL}\"}"
	API_URL="https://api.bitbucket.org/2.0/repositories/${GIT_REPO_OWNER}/${GIT_REPO_NAME}/commit/${GIT_COMMIT_HASH}/statuses/build"
	
	curl -sS --request POST "${API_URL}" \
		--header "Content-Type: application/json" \
		--user "${BITBUCKET_TOKEN}" \
		--data "${PAYLOAD}"
else
	echo "This command only works in Bitbucket Pipelines"
fi
